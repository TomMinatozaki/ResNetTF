{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import os\n",
    "from setting import *\n",
    "import cv2\n",
    "import pickle\n",
    "#from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from functions import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMG_H, IMG_W = 300, 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SSDHook(feature_map, hook_id):\n",
    "        \"\"\"\n",
    "        Takes input feature map, output the predictions tensor\n",
    "        hook_id is for variable_scope unqie string ID\n",
    "        \"\"\"\n",
    "        with tf.variable_scope('ssd_hook_' + hook_id):\n",
    "            # Note we have linear activation (i.e. no activation function)\n",
    "            net_conf = slim.conv2d(feature_map, NUM_PRED_CONF, [3, 3], activation_fn=None, scope='conv_conf')\n",
    "            net_conf = tf.contrib.layers.flatten(net_conf)\n",
    "\n",
    "            net_loc = slim.conv2d(feature_map, NUM_PRED_LOC, [3, 3], activation_fn=None, scope='conv_loc')\n",
    "            net_loc = tf.contrib.layers.flatten(net_loc)\n",
    "\n",
    "        return net_conf, net_loc\n",
    "def AlexNet():\n",
    "        \n",
    "        # Image batch tensor and dropout keep prob placeholders\n",
    "        x = tf.placeholder(tf.float32, [None, IMG_H, IMG_W, NUM_CHANNELS], name='x')\n",
    "        is_training = tf.placeholder(tf.bool, name='is_training')\n",
    "\n",
    "        # Classification and localization predictions\n",
    "        preds_conf = []  # conf -> classification b/c confidence loss -> classification loss\n",
    "        preds_loc = []\n",
    "\n",
    "        # Use batch normalization for all convolution layers\n",
    "        # FIXME: Not sure why setting is_training is not working well\n",
    "        #with slim.arg_scope([slim.conv2d], normalizer_fn=slim.batch_norm, normalizer_params={'is_training': is_training}):\n",
    "        with slim.arg_scope([slim.conv2d], normalizer_fn=slim.batch_norm, normalizer_params={'is_training': True},\\\n",
    "                weights_regularizer=slim.l2_regularizer(scale=REG_SCALE)):\n",
    "            net = slim.conv2d(x, 64, [11, 11], 3, padding='VALID', scope='conv1')\n",
    "            #net = slim.conv2d(x, 64, [7, 7], 2, padding='SAME', scope='conv1')\n",
    "            net = slim.max_pool2d(net, [3, 3], 2,padding='SAME',scope='pool1')\n",
    "            net = slim.conv2d(net, 192, [5, 5],2, scope='conv2')\n",
    "\n",
    "            net_conf, net_loc = SSDHook(net, 'conv2')\n",
    "            preds_conf.append(net_conf)\n",
    "            preds_loc.append(net_loc)\n",
    "\n",
    "            #net = slim.max_pool2d(net, [3, 3], 2, scope='pool2')\n",
    "            net = slim.max_pool2d(net, [3, 3], 2,padding='SAME', scope='pool2')\n",
    "            net = slim.conv2d(net, 384, [3, 3], scope='conv3')\n",
    "            net = slim.conv2d(net, 384, [3, 3], scope='conv4')\n",
    "            net = slim.conv2d(net, 256, [3, 3], scope='conv5')\n",
    "\n",
    "            # The following layers added for SSD\n",
    "            net = slim.conv2d(net, 1024, [3, 3], scope='conv6')\n",
    "            net = slim.conv2d(net, 1024, [1, 1], scope='conv7')\n",
    "\n",
    "            net_conf, net_loc = SSDHook(net, 'conv7')\n",
    "            preds_conf.append(net_conf)\n",
    "            preds_loc.append(net_loc)\n",
    "\n",
    "            net = slim.conv2d(net, 256, [1, 1], scope='conv8')\n",
    "            net = slim.conv2d(net, 512, [3, 3], 2, scope='conv8_2')\n",
    "\n",
    "            net_conf, net_loc = SSDHook(net, 'conv8_2')\n",
    "            preds_conf.append(net_conf)\n",
    "            preds_loc.append(net_loc)\n",
    "\n",
    "            net = slim.conv2d(net, 128, [1, 1], scope='conv9')\n",
    "            net = slim.conv2d(net, 256, [3, 3], 2, scope='conv9_2')\n",
    "\n",
    "            net_conf, net_loc = SSDHook(net, 'conv9_2')\n",
    "            preds_conf.append(net_conf)\n",
    "            preds_loc.append(net_loc)\n",
    "            \n",
    "            net = slim.conv2d(net, 128, [1, 1], scope='conv10')\n",
    "            net = slim.conv2d(net, 256, [3, 3], 2, scope='conv10_2')\n",
    "            \n",
    "            net_conf, net_loc = SSDHook(net, 'conv10_2')\n",
    "            preds_conf.append(net_conf)\n",
    "            preds_loc.append(net_loc)\n",
    "\n",
    "        # Concatenate all preds together into 1 vector, for both classification and localization predictions\n",
    "        final_pred_conf = tf.concat(preds_conf,1)\n",
    "        final_pred_loc = tf.concat(preds_loc,1)\n",
    "\n",
    "        # Return a dictionary of {tensor_name: tensor_reference}\n",
    "        ret_dict = {\n",
    "            'x': x,\n",
    "            'y_pred_conf': final_pred_conf,\n",
    "            'y_pred_loc': final_pred_loc,\n",
    "            'is_training': is_training,\n",
    "        }\n",
    "        return ret_dict\n",
    "def SSDModel():\n",
    "        \"\"\"\n",
    "        Wrapper around the model and model helper\n",
    "        Returns dict of relevant tensor references\n",
    "        \"\"\"\n",
    "       \n",
    "        model = AlexNet()\n",
    "        model_helper = ModelHelper(model['y_pred_conf'], model['y_pred_loc'])\n",
    "\n",
    "        ssd_model = {}\n",
    "        for k in model.keys():\n",
    "            ssd_model[k] = model[k]\n",
    "        for k in model_helper.keys():\n",
    "            ssd_model[k] = model_helper[k]\n",
    "\n",
    "        return ssd_model\n",
    "def ModelHelper(y_pred_conf, y_pred_loc):\n",
    "        \"\"\"\n",
    "        Define loss function, optimizer, predictions, and accuracy metric\n",
    "        Loss includes confidence loss and localization loss\n",
    "        conf_loss_mask is created at batch generation time, to mask the confidence losses\n",
    "        It has 1 at locations w/ positives, and 1 at select negative locations\n",
    "        such that negative-to-positive ratio of NEG_POS_RATIO is satisfied\n",
    "        Arguments:\n",
    "            * y_pred_conf: Class predictions from model,\n",
    "                a tensor of shape [batch_size, num_feature_map_cells * num_defaul_boxes * num_classes]\n",
    "            * y_pred_loc: Localization predictions from model,\n",
    "                a tensor of shape [batch_size, num_feature_map_cells * num_defaul_boxes * 4]\n",
    "        Returns relevant tensor references\n",
    "        \"\"\"\n",
    "        num_total_preds = 0\n",
    "        for fm_size in FM_SIZES:\n",
    "            num_total_preds += fm_size[0] * fm_size[1] * NUM_DEFAULT_BOXES\n",
    "        num_total_preds_conf = num_total_preds * NUM_CLASSES\n",
    "        num_total_preds_loc  = num_total_preds * 4\n",
    "\n",
    "        # Input tensors\n",
    "        y_true_conf = tf.placeholder(tf.int32, [None, num_total_preds], name='y_true_conf')  # classification ground-truth labels\n",
    "        y_true_loc  = tf.placeholder(tf.float32, [None, num_total_preds_loc], name='y_true_loc')  # localization ground-truth labels\n",
    "        conf_loss_mask = tf.placeholder(tf.float32, [None, num_total_preds], name='conf_loss_mask')  # 1 mask \"bit\" per def. box\n",
    "\n",
    "        # Confidence loss\n",
    "        logits = tf.reshape(y_pred_conf, [-1, num_total_preds, NUM_CLASSES])\n",
    "        print(\"pred shape:\")\n",
    "        print(logits.shape)\n",
    "        print(\"true shape:\")\n",
    "        print(y_true_conf.shape)\n",
    "        conf_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,labels=y_true_conf)\n",
    "        #conf_loss = tf.metrics.sparse_softmax_cross_entropy_with_logits(labels=labels,logits=logits)\n",
    "        \n",
    "        conf_loss = conf_loss_mask * conf_loss  # \"zero-out\" the loss for don't-care negatives\n",
    "        conf_loss = tf.reduce_sum(conf_loss)\n",
    "\n",
    "        # Localization loss (smooth L1 loss)\n",
    "        # loc_loss_mask is analagous to conf_loss_mask, except 4 times the size\n",
    "        print(y_true_loc)\n",
    "        print(y_pred_loc)\n",
    "        diff = y_true_loc - y_pred_loc\n",
    "\n",
    "        loc_loss_l2 = 0.5 * (diff**2.0)\n",
    "        loc_loss_l1 = tf.abs(diff) - 0.5\n",
    "        smooth_l1_condition = tf.less(tf.abs(diff), 1.0)\n",
    "        loc_loss = tf.where(smooth_l1_condition, loc_loss_l2, loc_loss_l1)\n",
    "\n",
    "        loc_loss_mask = tf.minimum(y_true_conf, 1)  # have non-zero localization loss only where we have matching ground-truth box\n",
    "        loc_loss_mask = tf.to_float(loc_loss_mask)\n",
    "        loc_loss_mask = tf.stack([loc_loss_mask] * 4, axis=2)  # [0, 1, 1] -> [[[0, 0, 0, 0], [1, 1, 1, 1], [1, 1, 1, 1]], ...]\n",
    "        loc_loss_mask = tf.reshape(loc_loss_mask, [-1, num_total_preds_loc])  # removing the inner-most dimension of above\n",
    "        loc_loss = loc_loss_mask * loc_loss\n",
    "        loc_loss = tf.reduce_sum(loc_loss)\n",
    "\n",
    "        # Weighted average of confidence loss and localization loss\n",
    "        # Also add regularization loss\n",
    "        #loss = conf_loss + LOC_LOSS_WEIGHT * loc_loss + tf.reduce_sum(slim.losses.get_regularization_losses())\n",
    "        loss = conf_loss + LOC_LOSS_WEIGHT * loc_loss + 0.001*tf.reduce_sum(tf.losses.get_regularization_losses())\n",
    "        optimizer = OPT.minimize(loss)\n",
    "\n",
    "        #reported_loss = loss #tf.reduce_sum(loss, 1)  # DEBUG\n",
    "\n",
    "        # Class probabilities and predictions\n",
    "        probs_all = tf.nn.softmax(logits)\n",
    "        probs, preds_conf = tf.nn.top_k(probs_all)  # take top-1 probability, and the index is the predicted class\n",
    "        probs = tf.reshape(probs, [-1, num_total_preds])\n",
    "        preds_conf = tf.reshape(preds_conf, [-1, num_total_preds])\n",
    "\n",
    "        # Return a dictionary of {tensor_name: tensor_reference}\n",
    "        ret_dict = {\n",
    "            'y_true_conf': y_true_conf,\n",
    "            'y_true_loc': y_true_loc,\n",
    "            'conf_loss_mask': conf_loss_mask,\n",
    "            'optimizer': optimizer,\n",
    "            'conf_loss': conf_loss,\n",
    "            'loc_loss': loc_loss,\n",
    "            'loss': loss,\n",
    "            'probs': probs,\n",
    "            'probs_all': probs_all,\n",
    "            'preds_conf': preds_conf,\n",
    "            'preds_loc': y_pred_loc,\n",
    "        }\n",
    "        return ret_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"conv233/Relu:0\", shape=(?, 25, 25, 192), dtype=float32)\n",
      "Tensor(\"ssd_hook_conv2323/Flatten_1/flatten/Reshape:0\", shape=(?, 30000), dtype=float32)\n",
      "Tensor(\"conv7/Relu:0\", shape=(?, 13, 13, 1024), dtype=float32)\n",
      "Tensor(\"ssd_hook_conv7/Flatten_1/flatten/Reshape:0\", shape=(?, 8112), dtype=float32)\n",
      "Tensor(\"conv8_2/Relu:0\", shape=(?, 7, 7, 512), dtype=float32)\n",
      "Tensor(\"ssd_hook_conv8_2/Flatten_1/flatten/Reshape:0\", shape=(?, 2352), dtype=float32)\n",
      "Tensor(\"conv9_2/Relu:0\", shape=(?, 4, 4, 256), dtype=float32)\n",
      "Tensor(\"ssd_hook_conv9_2/Flatten_1/flatten/Reshape:0\", shape=(?, 768), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, [None, IMG_H, IMG_W, NUM_CHANNELS], name='x')\n",
    "net = slim.conv2d(x, 64, [11, 11], 3, padding='VALID', scope='conv1232')\n",
    "net = slim.max_pool2d(net, [3, 3], 2,padding='SAME',scope='pool1233')\n",
    "net = slim.conv2d(net, 192, [5, 5],2, scope='conv233')\n",
    "net_conf, net_loc = SSDHook(net, 'conv2323')\n",
    "print(net)\n",
    "print(net_loc)\n",
    "net = slim.max_pool2d(net, [3, 3], 2,padding='SAME', scope='pool2')\n",
    "net = slim.conv2d(net, 384, [3, 3], scope='conv3')\n",
    "net = slim.conv2d(net, 384, [3, 3], scope='conv4')\n",
    "net = slim.conv2d(net, 256, [3, 3], scope='conv5')\n",
    "net = slim.conv2d(net, 1024, [3, 3], scope='conv6')\n",
    "net = slim.conv2d(net, 1024, [1, 1], scope='conv7')\n",
    "net_conf, net_loc = SSDHook(net, 'conv7')\n",
    "print(net)\n",
    "print(net_loc)\n",
    "net = slim.conv2d(net, 256, [1, 1], scope='conv8')\n",
    "net = slim.conv2d(net, 512, [3, 3], 2, scope='conv8_2')\n",
    "net_conf, net_loc = SSDHook(net, 'conv8_2')\n",
    "print(net)\n",
    "print(net_loc)\n",
    "net = slim.conv2d(net, 128, [1, 1], scope='conv9')\n",
    "net = slim.conv2d(net, 256, [3, 3], 2, scope='conv9_2')\n",
    "net_conf, net_loc = SSDHook(net, 'conv9_2')\n",
    "print(net)\n",
    "print(net_loc)\n",
    "net = slim.conv2d(net, 128, [1, 1], scope='conv10')\n",
    "net = slim.conv2d(net, 256, [3, 3], 2, scope='conv10_2')\n",
    "net_conf, net_loc = SSDHook(net, 'conv10_2')\n",
    "print(net)\n",
    "print(net_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('D:\\Data\\VOC2007')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=np.load('./3000_data_prep.npy')\n",
    "train=train[()]\n",
    "for key in train.keys():\n",
    "    train[key]['y_true_conf']=train[key]['y_true_conf'].astype(int)\n",
    "X_train = []\n",
    "y_train_conf = []\n",
    "y_train_loc = []\n",
    "k=0\n",
    "for img_name in train.keys():\n",
    "        img_file=cv2.imread(os.path.join('./ResizedImage//',img_name))\n",
    "        X_train.append(img_file)\n",
    "        y_train_conf.append(train[img_name]['y_true_conf'])\n",
    "        y_train_loc.append(train[img_name]['y_true_loc'])\n",
    "X_train = np.array(X_train)\n",
    "y_train_conf = np.array(y_train_conf)\n",
    "y_train_loc = np.array(y_train_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred shape:\n",
      "(?, 10356, 24)\n",
      "true shape:\n",
      "(?, 10356)\n",
      "Tensor(\"y_true_loc:0\", shape=(?, 41424), dtype=float32)\n",
      "Tensor(\"concat_1:0\", shape=(?, 41424), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "sess=tf.Session()\n",
    "model=SSDModel()\n",
    "x=model['x']\n",
    "y_true_conf=model['y_true_conf']\n",
    "y_true_loc=model['y_true_loc']\n",
    "conf_loss_mask=model['conf_loss_mask']\n",
    "is_training=model['is_training']\n",
    "conf_loss=model['conf_loss']\n",
    "loc_loss=model['loc_loss']\n",
    "reported_loss=model['loss']\n",
    "optimizer = model['optimizer']\n",
    "\n",
    "\n",
    "probs_all=model['probs_all']\n",
    "preds_conf = model['preds_conf']\n",
    "preds_loc = model['preds_loc']\n",
    "probs = model['probs']\n",
    "\n",
    "\n",
    "saver=tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_path='./12-31_model.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./12-31_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "saver.restore(sess,model_path)\n",
    "\n",
    "#sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer=tf.train.GradientDescentOptimizer(learning_rate=1e-3).minimize(model['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new epoch\n",
      "231291.0\n",
      "new epoch\n",
      "93544.8\n",
      "new epoch\n",
      "60028.4\n",
      "new epoch\n",
      "44351.0\n",
      "new epoch\n",
      "35415.6\n",
      "new epoch\n",
      "29648.7\n",
      "new epoch\n",
      "25556.0\n",
      "new epoch\n",
      "22458.3\n",
      "new epoch\n",
      "20019.7\n",
      "new epoch\n",
      "18040.2\n",
      "new epoch\n",
      "16421.6\n",
      "new epoch\n",
      "15065.7\n",
      "new epoch\n",
      "13922.9\n",
      "new epoch\n",
      "12946.7\n",
      "new epoch\n",
      "12094.4\n",
      "new epoch\n",
      "11358.5\n",
      "new epoch\n",
      "10707.5\n",
      "new epoch\n",
      "10125.6\n",
      "new epoch\n",
      "9607.87\n",
      "new epoch\n",
      "9135.7\n",
      "new epoch\n",
      "8713.51\n",
      "new epoch\n",
      "8325.94\n",
      "new epoch\n",
      "7968.91\n",
      "new epoch\n",
      "7641.91\n",
      "new epoch\n",
      "7340.0\n",
      "new epoch\n",
      "7060.29\n",
      "new epoch\n",
      "6802.22\n",
      "new epoch\n",
      "6557.9\n",
      "new epoch\n",
      "6335.03\n",
      "new epoch\n",
      "6122.0\n",
      "new epoch\n",
      "5924.52\n",
      "new epoch\n",
      "5743.78\n",
      "new epoch\n",
      "5569.12\n",
      "new epoch\n",
      "5407.46\n",
      "new epoch\n",
      "5253.32\n",
      "new epoch\n",
      "5110.8\n",
      "new epoch\n",
      "4975.37\n",
      "new epoch\n",
      "4844.54\n",
      "new epoch\n",
      "4724.5\n",
      "new epoch\n",
      "4608.5\n",
      "new epoch\n",
      "4500.32\n",
      "new epoch\n",
      "4398.03\n",
      "new epoch\n",
      "4301.45\n",
      "new epoch\n",
      "4203.72\n",
      "new epoch\n",
      "4119.23\n",
      "new epoch\n",
      "4032.86\n",
      "new epoch\n",
      "3952.14\n",
      "new epoch\n",
      "3874.97\n",
      "new epoch\n",
      "3799.84\n",
      "new epoch\n",
      "3731.94\n",
      "new epoch\n",
      "3661.08\n",
      "new epoch\n",
      "3594.22\n",
      "new epoch\n",
      "3534.23\n",
      "new epoch\n",
      "3475.27\n",
      "new epoch\n",
      "3414.55\n",
      "new epoch\n",
      "3360.44\n",
      "new epoch\n",
      "3309.48\n",
      "new epoch\n",
      "3255.48\n",
      "new epoch\n",
      "3207.42\n",
      "new epoch\n",
      "3158.73\n",
      "new epoch\n",
      "3112.81\n",
      "new epoch\n",
      "3069.91\n",
      "new epoch\n",
      "3023.01\n",
      "new epoch\n",
      "2984.0\n",
      "new epoch\n",
      "2943.68\n",
      "new epoch\n",
      "2902.27\n",
      "new epoch\n",
      "2865.26\n",
      "new epoch\n",
      "2826.91\n",
      "new epoch\n",
      "2792.07\n",
      "new epoch\n",
      "2755.62\n",
      "new epoch\n",
      "2720.63\n",
      "new epoch\n",
      "2687.39\n",
      "new epoch\n",
      "2656.42\n",
      "new epoch\n",
      "2626.46\n",
      "new epoch\n",
      "2595.09\n",
      "new epoch\n",
      "2564.04\n",
      "new epoch\n",
      "2537.91\n",
      "new epoch\n",
      "2509.42\n",
      "new epoch\n",
      "2479.33\n",
      "new epoch\n",
      "2453.8\n",
      "new epoch\n",
      "2425.79\n",
      "new epoch\n",
      "2400.54\n",
      "new epoch\n",
      "2376.78\n",
      "new epoch\n",
      "2354.16\n",
      "new epoch\n",
      "2326.36\n",
      "new epoch\n",
      "2304.25\n",
      "new epoch\n",
      "2280.01\n",
      "new epoch\n",
      "2259.55\n",
      "new epoch\n",
      "2234.31\n",
      "new epoch\n",
      "2215.91\n",
      "new epoch\n",
      "2189.6\n",
      "new epoch\n",
      "2169.08\n",
      "new epoch\n",
      "2151.47\n",
      "new epoch\n",
      "2131.43\n",
      "new epoch\n",
      "2110.25\n",
      "new epoch\n",
      "2086.23\n",
      "new epoch\n",
      "2069.51\n",
      "new epoch\n",
      "2050.42\n",
      "new epoch\n",
      "2031.37\n",
      "new epoch\n",
      "2013.22\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100 ):\n",
    "    train_gen=next_batch(X_train,y_train_conf,y_train_loc,BATCH_SIZE)\n",
    "    num_batches_train = int(math.ceil(X_train.shape[0] / BATCH_SIZE))\n",
    "    losses=[]\n",
    "    \n",
    "    for i in range(num_batches_train):\n",
    "        images, y_true_conf_gen, y_true_loc_gen, conf_loss_mask_gen = next(train_gen)\n",
    "        _, loss = sess.run([optimizer, reported_loss], feed_dict={x: images,y_true_conf: y_true_conf_gen,\n",
    "                        y_true_loc: y_true_loc_gen,conf_loss_mask: conf_loss_mask_gen,\n",
    "                        is_training: True\n",
    "                    })\n",
    "        losses.append(loss)\n",
    "        #print(loss)\n",
    "    print(\"new epoch\")\n",
    "    losses=np.array(losses)\n",
    "    print(np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1006.85\n",
      "33.935\n",
      "19.02\n",
      "16.07\n",
      "14.6203\n",
      "13.8769\n",
      "13.0323\n",
      "12.7585\n",
      "12.1973\n",
      "11.8259\n",
      "11.5699\n",
      "11.3492\n",
      "11.1341\n",
      "10.9567\n",
      "10.816\n",
      "10.626\n",
      "10.471\n",
      "10.3767\n"
     ]
    }
   ],
   "source": [
    "optimizer=tf.train.GradientDescentOptimizer(learning_rate=1e-3).minimize(model['loss'])\n",
    "for epoch in range(180 ):\n",
    "    train_gen=next_batch(X_train,y_train_conf,y_train_loc,BATCH_SIZE)\n",
    "    num_batches_train = int(math.ceil(X_train.shape[0] / BATCH_SIZE))\n",
    "    losses=[]\n",
    "    \n",
    "    for i in range(num_batches_train):\n",
    "        images, y_true_conf_gen, y_true_loc_gen, conf_loss_mask_gen = next(train_gen)\n",
    "        _, loss = sess.run([optimizer, reported_loss], feed_dict={x: images,y_true_conf: y_true_conf_gen,\n",
    "                        y_true_loc: y_true_loc_gen,conf_loss_mask: conf_loss_mask_gen,\n",
    "                        is_training: True\n",
    "                    })\n",
    "        losses.append(loss)\n",
    "        #print(loss)\n",
    "    if epoch % 10 ==0 :\n",
    "    \n",
    "        losses=np.array(losses)\n",
    "        print(np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.0864\n",
      "13.9568\n",
      "28.1451\n",
      "12.3073\n",
      "25.7974\n",
      "10.351\n",
      "110.542\n",
      "12.2519\n",
      "39.2978\n",
      "13.8176\n",
      "27.6842\n",
      "12.3249\n",
      "24.6696\n",
      "10.2453\n",
      "33.3856\n",
      "11.3851\n",
      "25.1858\n",
      "13.29\n",
      "20.1644\n",
      "11.9381\n",
      "18.5034\n",
      "9.84533\n",
      "21.6579\n",
      "10.7594\n",
      "20.3436\n",
      "12.8856\n",
      "17.1574\n",
      "11.6079\n",
      "15.4908\n",
      "9.54682\n",
      "17.1413\n",
      "10.3696\n",
      "17.9348\n",
      "12.6066\n",
      "15.5831\n",
      "11.3614\n",
      "13.9004\n",
      "9.29078\n",
      "15.033\n",
      "10.0765\n",
      "16.6161\n",
      "12.3613\n",
      "14.5796\n",
      "11.185\n",
      "12.8064\n",
      "9.12253\n",
      "13.6669\n",
      "9.86864\n",
      "15.682\n",
      "12.1869\n",
      "13.8791\n",
      "11.0223\n",
      "12.0157\n",
      "8.99449\n",
      "12.8267\n",
      "9.69599\n",
      "14.9512\n",
      "12.0471\n",
      "13.3559\n",
      "10.8847\n",
      "11.5139\n",
      "8.86366\n",
      "12.208\n",
      "9.52433\n",
      "14.4769\n",
      "11.9102\n",
      "12.9463\n",
      "10.7772\n",
      "11.0322\n",
      "8.76855\n",
      "11.7434\n",
      "9.42166\n",
      "14.0496\n",
      "11.8033\n",
      "12.5936\n",
      "10.6601\n",
      "10.731\n",
      "8.683\n",
      "11.376\n",
      "9.32\n",
      "13.7403\n",
      "11.6972\n",
      "12.3291\n",
      "10.5767\n",
      "10.4068\n",
      "8.59221\n",
      "11.1028\n",
      "9.22478\n",
      "13.4619\n",
      "11.6253\n",
      "12.097\n",
      "10.5164\n",
      "10.2023\n",
      "8.53227\n",
      "10.8608\n",
      "9.15996\n",
      "13.2483\n",
      "11.536\n",
      "11.9004\n",
      "10.4471\n",
      "9.9984\n",
      "8.46695\n",
      "10.6631\n",
      "9.07038\n",
      "13.0544\n",
      "11.4818\n",
      "11.7321\n",
      "10.388\n",
      "9.8159\n",
      "8.43822\n",
      "10.4747\n",
      "9.00622\n",
      "12.8947\n",
      "11.4275\n",
      "11.5778\n",
      "10.3272\n",
      "9.68382\n",
      "8.37327\n",
      "10.3243\n",
      "8.93338\n",
      "12.7473\n",
      "11.3558\n",
      "11.4566\n",
      "10.2834\n",
      "9.55056\n",
      "8.33294\n",
      "10.1664\n",
      "8.89627\n",
      "12.6134\n",
      "11.2994\n",
      "11.3362\n",
      "10.2287\n",
      "9.43441\n",
      "8.27514\n",
      "10.0673\n",
      "8.86008\n",
      "12.5074\n",
      "11.2638\n",
      "11.2318\n",
      "10.1839\n",
      "9.34307\n",
      "8.23896\n",
      "9.95597\n",
      "8.79637\n",
      "12.3892\n",
      "11.2807\n",
      "11.1559\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-c8e93f6b2b73>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m                 _, loss = sess.run([optimizer, reported_loss], feed_dict={x: images,y_true_conf: y_true_conf_gen,\n\u001b[0;32m     13\u001b[0m                                 \u001b[0my_true_loc\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_true_loc_gen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconf_loss_mask\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mconf_loss_mask_gen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m                                 \u001b[0mis_training\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m                             })\n\u001b[0;32m     16\u001b[0m                 \u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer=tf.train.GradientDescentOptimizer(learning_rate=1e-3).minimize(model['loss'])\n",
    "for period in range(20):\n",
    "    for npy_dir in npy_list:\n",
    "        train,X_train,y_train_conf,y_train_loc=change_trainset(npy_dir)\n",
    "        for epoch in range(15):\n",
    "            train_gen=next_batch(X_train,y_train_conf,y_train_loc,BATCH_SIZE)\n",
    "            num_batches_train = int(math.ceil(X_train.shape[0] / BATCH_SIZE))\n",
    "            losses=[]\n",
    "\n",
    "            for i in range(num_batches_train):\n",
    "                images, y_true_conf_gen, y_true_loc_gen, conf_loss_mask_gen = next(train_gen)\n",
    "                _, loss = sess.run([optimizer, reported_loss], feed_dict={x: images,y_true_conf: y_true_conf_gen,\n",
    "                                y_true_loc: y_true_loc_gen,conf_loss_mask: conf_loss_mask_gen,\n",
    "                                is_training: True\n",
    "                            })\n",
    "                losses.append(loss)\n",
    "                #print(loss)\n",
    "            if epoch % 10 ==0 :\n",
    "\n",
    "                losses=np.array(losses)\n",
    "                print(np.mean(losses))\n",
    "        del train\n",
    "        del X_train\n",
    "        del y_train_conf\n",
    "        del y_train_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del train\n",
    "del X_train\n",
    "del y_train_conf\n",
    "del y_train_loc\n",
    "train=np.load('./4305_data_prep.npy')\n",
    "train=train[()]\n",
    "for key in train.keys():\n",
    "    train[key]['y_true_conf']=train[key]['y_true_conf'].astype(int)\n",
    "X_train = []\n",
    "y_train_conf = []\n",
    "y_train_loc = []\n",
    "k=0\n",
    "for img_name in train.keys():\n",
    "        img_file=cv2.imread(os.path.join('./ResizedImage//',img_name))\n",
    "        X_train.append(img_file)\n",
    "        y_train_conf.append(train[img_name]['y_true_conf'])\n",
    "        y_train_loc.append(train[img_name]['y_true_loc'])\n",
    "X_train = np.array(X_train)\n",
    "y_train_conf = np.array(y_train_conf)\n",
    "y_train_loc = np.array(y_train_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "npy_list=['./1000_data_prep.npy','./2000_data_prep.npy','./3000_data_prep.npy','./4000_data_prep.npy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "npy_list=['./1000_data_prep.npy','./2000_data_prep.npy','./3000_data_prep.npy','./4000_data_prep.npy']\n",
    "def change_trainset(npy_dir):\n",
    "    train=np.load(npy_dir)\n",
    "    train=train[()]\n",
    "    for key in train.keys():\n",
    "        train[key]['y_true_conf']=train[key]['y_true_conf'].astype(int)\n",
    "    X_train = []\n",
    "    y_train_conf = []\n",
    "    y_train_loc = []\n",
    "    k=0\n",
    "    for img_name in train.keys():\n",
    "            img_file=cv2.imread(os.path.join('./ResizedImage//',img_name))\n",
    "            X_train.append(img_file)\n",
    "            y_train_conf.append(train[img_name]['y_true_conf'])\n",
    "            y_train_loc.append(train[img_name]['y_true_loc'])\n",
    "    X_train = np.array(X_train)\n",
    "    y_train_conf = np.array(y_train_conf)\n",
    "    y_train_loc = np.array(y_train_loc)\n",
    "    return train,X_train,y_train_conf,y_train_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.3915\n",
      "new epoch\n",
      "0.120379\n"
     ]
    }
   ],
   "source": [
    "\n",
    "images, y_true_conf_gen, y_true_loc_gen, conf_loss_mask_gen = next(train_gen)\n",
    "closs,lloss = sess.run( [conf_loss,loc_loss], feed_dict={x: images,y_true_conf: y_true_conf_gen,\n",
    "                y_true_loc: y_true_loc_gen,conf_loss_mask: conf_loss_mask_gen,\n",
    "                is_training: False\n",
    "            })\n",
    "print(closs)\n",
    "print(\"new epoch\")\n",
    "print(lloss)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images, y_true_conf_gen, y_true_loc_gen, conf_loss_mask_gen = next(train_gen)\n",
    "preds_conf_val, preds_loc_val, probs_val,probs_all_val = sess.run([preds_conf, preds_loc, probs, probs_all], feed_dict={x: images, is_training: False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k in range(7):\n",
    "    y_pred_conf=preds_conf_val[k]\n",
    "    y_pred_conf=y_pred_conf.astype('float32')\n",
    "    prob=probs_val[k]\n",
    "    y_pred_loc = preds_loc_val[k]\n",
    "    boxes = nms(y_pred_conf, y_pred_loc, prob)\n",
    "    image=images[k]\n",
    "    rectangled= image\n",
    "    for box in boxes:\n",
    "        box_coords = [int(round(ku)) for ku in box[0]]\n",
    "        box_cls = box[1]\n",
    "        rectangled = cv2.rectangle(image, tuple(box_coords[:2]), tuple(box_coords[2:]), (0,255,0))\n",
    "        rectangled = cv2.putText(rectangled,str(box_cls),(tuple(box_coords[:2])),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0, 0, 255),1)\n",
    "    cv2.imwrite('./Test/1-02-2_newt'+str(k)+'.jpg',rectangled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for k in range(7):\n",
    "    y_pred_conf=preds_conf_val[k]\n",
    "    y_pred_conf=y_pred_conf.astype('float32')\n",
    "    prob=probs_val[k]\n",
    "    y_pred_loc = preds_loc_val[k]\n",
    "    boxes = nms(y_pred_conf, y_pred_loc, prob)\n",
    "    image=images[k]\n",
    "    rectangled= image\n",
    "    for box in boxes:\n",
    "        box_coords = [int(round(ku)) for ku in box[0]]\n",
    "        box_cls = box[1]\n",
    "        rectangled = cv2.rectangle(image, tuple(box_coords[:2]), tuple(box_coords[2:]), (0,255,0))\n",
    "        rectangled = cv2.putText(rectangled,str(box_cls),(tuple(box_coords[:2])),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0, 0, 255),1)\n",
    "    cv2.imwrite('./Test/1-02-2_test6_'+str(k)+'.jpg',rectangled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nms(y_pred_conf, y_pred_loc, prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_conf[40:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CONF_THRESH=0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_boxes = []  # class -> [(x1, y1, x2, y2, prob), (...), ...]\n",
    "for h in range(3):\n",
    "    class_boxes.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CONF_THRESH = 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./1-02_model.ckpt'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We've Done 2000 Images For one time\n",
    "model_path='./1-02_model.ckpt'\n",
    "saver.save(sess,model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
